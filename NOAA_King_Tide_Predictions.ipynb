{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NOAA King Tide Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lAqrQORvqa0t",
        "3htUXNvDPZcQ",
        "OPr95Q_OrSbO"
      ],
      "authorship_tag": "ABX9TyO5X9tGBE3yLj6rFqXMOm0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robert-lemon-uhm/NOAA_King_Tide/blob/main/NOAA_King_Tide_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running, make sure the *Configuration Settings* below is correct.\n",
        "\n",
        "To run this notebook and generate the Google Sheets file, click `Runtime -> Run All`."
      ],
      "metadata": {
        "id": "0QxSVy9slXEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration Settings"
      ],
      "metadata": {
        "id": "Euda4M5iGpK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Range { run: \"auto\" }\n",
        "\n",
        "#@markdown Please select a start and end date.\n",
        "#@markdown This will be the range of king tide predictions.\n",
        "\n",
        "start_date = '2021-01-01' #@param {type:\"date\"}\n",
        "end_date = '2021-12-31' #@param {type:\"date\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Sj3SdoOxCiHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reasonable Times { run: \"auto\" }\n",
        "\n",
        "#@markdown Please select an earliest and latest time for reasonable tide predictions.\n",
        "#@markdown All tide predictions outside of this time range will be filtered out. \n",
        "#@markdown The earliest time cannot be later than the latest time.\n",
        "#@markdown \n",
        "#@markdown The time is formatted in 24-hour (military) time as follows: &nbsp;&nbsp;`HH:MM`\n",
        "#@markdown\n",
        "#@markdown The default is `07:00` - `19:00` (7AM  - 7PM).\n",
        "\n",
        "earliest_time = '07:00' #@param {type:\"string\"}\n",
        "latest_time = '19:00' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "29CKp940EtJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Number of Predictions { run: \"auto\" }\n",
        "\n",
        "#@markdown Please specify the number of predictions to be generated. \n",
        "#@markdown This is the amount of top predictions that will appear on each page for each station, \n",
        "#@markdown including the composite score table.\n",
        "#@markdown\n",
        "#@markdown The number of desired predictions cannot exceed the number of days between the start and end dates.\n",
        "\n",
        "x_top_tides =  25#@param {type:\"integer\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "talI5r5gH2HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Composite Score Settings { run: \"auto\" }\n",
        "\n",
        "#@markdown Please select a geographical region to get tide predictions for.\n",
        "\n",
        "region = 'Hawaii' #@param ['Northern Mariana Islands', 'Federated States of Micronesia', 'Marshall Islands', 'Hawaii', 'American Samoa']\n",
        "\n",
        "#@markdown Please also enter the primary station ID to use for the composite score table.\n",
        "#@markdown The default station ID is `1612340 (Honolulu)`. Station IDs can be found [here](https://tidesandcurrents.noaa.gov/tide_predictions.html?gid=1749#listing).\n",
        "\n",
        "primary_station_ID =  1612340#@param {type:\"integer\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QhFT6PXJEzQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** If you double click on the forms above, it will display the code for them. If you accidentally do this, you can always hide the code by double clicking the form again. Alternatively, single clicking on the form, clicking the three vertical dots at the top right of the form, and selecting `Form` -> `Hide Code` will also hide the code."
      ],
      "metadata": {
        "id": "g36RuP47zy19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Code"
      ],
      "metadata": {
        "id": "IE4ZRrtJlULb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports and Methods"
      ],
      "metadata": {
        "id": "lAqrQORvqa0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26C2w8S3Yl1o"
      },
      "outputs": [],
      "source": [
        "# Default python3 imports\n",
        "import json\n",
        "import operator\n",
        "from urllib.request import urlopen\n",
        "from datetime import datetime\n",
        "\n",
        "# Third party data science imports (installed by default on Google Colab)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Third party google drive imports (installed by default on Google Colab)\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_station_name(station_ID):\n",
        "  '''\n",
        "  DESC:   A function that uses the NOAA metadata API to get the name of a tide prediction station,\n",
        "          given its station ID. \n",
        "          API LINK: https://tidesandcurrents.noaa.gov/api-helper/url-generator.html\n",
        "\n",
        "  INPUT:  'station_ID'    the ID of the station to get the name of\n",
        "\n",
        "  OUTPUT: the name of the station\n",
        "  '''\n",
        "  API_response = urlopen(f\"https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations/{station_ID}.json?units=english\")\n",
        "  station_json = json.loads(API_response.read())\n",
        "  return station_json['stations'][0]['name']"
      ],
      "metadata": {
        "id": "XO1F5dVkwGka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_URL(start_date, end_date, station_ID, time_zone='lst', units='english'):\n",
        "  '''\n",
        "  DESC:   A function to build the NOAA API URL for tide predictions.\n",
        "          API LINK: https://tidesandcurrents.noaa.gov/api-helper/url-generator.html\n",
        "\n",
        "  INPUT:  'start_date'    the start date for the data (format \"YYYYMMDD\")\n",
        "          'end_date'      the end date for the data (format \"YYYYMMDD\")\n",
        "          'station_ID'    the ID of the station to get tide data from\n",
        "          'time_zone'     (OPTIONAL) the time zone\n",
        "                              possible options: \"gmt\", \"lst\", \"lst_ldt\" (default is \"lst\")\n",
        "          'units'         (OPTIONAL) the unit of measurement for tide prediction\n",
        "                              possible options: \"english\", \"metric\" (default is \"english\")\n",
        "\n",
        "  OUTPUT: the NOAA API URL containing the data in JSON format\n",
        "  '''\n",
        "\n",
        "  assert time_zone == 'lst' or time_zone == 'gmt' or time_zone == 'lst_ldt', \\\n",
        "         \"ERROR: Incorrect input for 'time_zone' parameter!\"\n",
        "  assert units == 'english' or units == 'metric', \\\n",
        "         \"ERROR: Incorrect input for 'units' parameter!\"\n",
        "\n",
        "  return \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter?\" \\\n",
        "    + f\"begin_date={start_date}&end_date={end_date}&station={station_ID}&\" + \\\n",
        "    f\"product=predictions&datum=MLLW&time_zone={time_zone}\" + \\\n",
        "    f\"&interval=hilo&units={units}&format=json\""
      ],
      "metadata": {
        "id": "YRNipDjXZFFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_API_data(url):\n",
        "  '''\n",
        "  DESC:   A function to download a .json file from a NOAA API URL.\n",
        "          Data is stored in a dictionary {date : tide level}. Assumes \n",
        "          that a valid URL is passed in (use the 'create_URL' method).\n",
        "\n",
        "  INPUT:  'url'   the NOAA API URL for the data download\n",
        "\n",
        "  OUTPUT: the downloaded data, in a dictionary\n",
        "  '''\n",
        "\n",
        "  API_response = urlopen(url)\n",
        "  json_data = json.loads(API_response.read())\n",
        "  return {x['t']: float(x['v']) for x in json_data['predictions']}"
      ],
      "metadata": {
        "id": "x9LhuU24ZML1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_unreasonable_times(df):\n",
        "  '''\n",
        "  DESC:   A function to remove rows of a dataframe whose time is unreasonable.\n",
        "          This assumes that the index column of the dataframe is a date STRING.\n",
        "\n",
        "  INPUT:  'df'   The dataframe to filter\n",
        "\n",
        "  OUTPUT: the inputted dataframe, with unreasonably timed rows removed\n",
        "  '''\n",
        "\n",
        "  # Get min and max times\n",
        "  min_time = datetime.strptime(earliest_time, '%H:%M').time()\n",
        "  max_time = datetime.strptime(latest_time, '%H:%M').time()\n",
        "  # Remove unreasonable times from df\n",
        "  return df[[min_time < datetime.strptime(time, '%Y-%m-%d %H:%M').time() < max_time \n",
        "                for time in df.index.values.tolist()]]"
      ],
      "metadata": {
        "id": "OKSfeAbWmadZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consolidate_dates(df):\n",
        "  '''\n",
        "  DESC:   A function that consolidates values by date. Only the max value for \n",
        "          each date is kept, all other rows with that date is dropped. The \n",
        "          index is then simplified to only include the date, not the time. It \n",
        "          is assumed that the index column of the dataframe is a date STRING, \n",
        "          called 'Date'. \n",
        "\n",
        "  INPUT:  'df'    The dataframe to considate\n",
        "\n",
        "  OUTPUT: the inputted dataframe, with dates consolidated\n",
        "  '''\n",
        "\n",
        "  # Drop the time\n",
        "  df['Date'] = [x.split()[0] for x in df.index]\n",
        "  df = df.set_index('Date')\n",
        "  # Keep only the max for each date\n",
        "  return df.groupby('Date').max()"
      ],
      "metadata": {
        "id": "uPixStlsqk5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_and_rank(df, station_name):\n",
        "  '''\n",
        "  DESC:   A function that sorts a dataframe by its 'station_name' column.\n",
        "          After sorting, it overwrites this column with the row's rank.\n",
        "\n",
        "  INPUT:  'df'            The dataframe to sort and rank\n",
        "          'station_name'  The name of the column to sort and rank\n",
        "\n",
        "  OUTPUT: the df, sorted and ranked\n",
        "  '''\n",
        "\n",
        "  df = df.sort_values(station_name, ascending=False)\n",
        "  df[station_name] = np.arange(1, df.shape[0]+1, dtype=int)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ZrkN-AqNr8lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Driver Code"
      ],
      "metadata": {
        "id": "3htUXNvDPZcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing of start/end date Configuration Settings"
      ],
      "metadata": {
        "id": "bE89Tx7vyOow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reformat start and end dates\n",
        "start_date = datetime.strptime(start_date, \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n",
        "end_date = datetime.strptime(end_date, \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n",
        "\n",
        "# Check the validity of the requested number of predictions\n",
        "num_of_days = (datetime.strptime(end_date, \"%Y%m%d\") - datetime.strptime(start_date, \"%Y%m%d\")).days\n",
        "assert num_of_days >= x_top_tides\n",
        "assert num_of_days > 1\n",
        "\n",
        "# Check the validity of the reasonable time frame\n",
        "assert datetime.strptime(earliest_time, \"%H:%M\") < datetime.strptime(latest_time, \"%H:%M\")"
      ],
      "metadata": {
        "id": "fhNxt40wVsA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing of station/region Configuration Settings"
      ],
      "metadata": {
        "id": "VBPcNiNnyDGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists of all harmonic stations for each region\n",
        "NMI_station_IDs = [1633227, 1630000, 1631428]\n",
        "FSM_station_IDs = [1840000]\n",
        "MI_station_IDs = [1890000, 1820000]\n",
        "H_station_IDs = [1611347, 1611400, 1612366, 1612404, 1612340, 1612480, 1613198, 1615680, 1617433, 1617760]\n",
        "AS_station_IDs = [1770000]\n",
        "\n",
        "# Determine which region was selected\n",
        "if region == 'Northern Mariana Islands':\n",
        "  station_IDs = NMI_station_IDs.copy()\n",
        "elif region == 'Federated States of Micronesia':\n",
        "  station_IDs = FSM_station_IDs.copy()\n",
        "elif region == 'Marshall Islands':\n",
        "  station_IDs = MI_station_IDs.copy()\n",
        "elif region == 'American Samoa':\n",
        "  station_IDs = AS_station_IDs.copy()\n",
        "else: # default is 'Hawaii'\n",
        "  station_IDs = H_station_IDs.copy()\n",
        "\n",
        "# Build stations dict\n",
        "stations = {get_station_name(station_ID): station_ID for station_ID in station_IDs}\n",
        "\n",
        "# Determine if multiple stations have been selected (including primary station)\n",
        "has_multiple = True\n",
        "if len(stations.keys()) == 1 and primary_station_ID in stations.values():\n",
        "  has_multiple = False"
      ],
      "metadata": {
        "id": "FRFCohmJPZRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial setup for creating the google sheets file"
      ],
      "metadata": {
        "id": "FNMeuL8FkvI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to google drive\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Create new sheets doc\n",
        "start_date_formatted = datetime.strptime(start_date, \"%Y%m%d\").strftime(\"%m.%d.%Y\")\n",
        "end_date_formatted = datetime.strptime(end_date, \"%Y%m%d\").strftime(\"%m.%d.%Y\")\n",
        "sh = gc.create(f\"{region} [{start_date_formatted} - {end_date_formatted}]\")"
      ],
      "metadata": {
        "id": "GSPwczsGY1w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download, data wrangling, and google sheets upload of primary station used in composite table (probably Honolulu)."
      ],
      "metadata": {
        "id": "k9G7xdmFkyBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get primary station name\n",
        "primary_station_name = ''\n",
        "if primary_station_ID in stations.values():\n",
        "  primary_station_name = list(stations.keys())[list(stations.values()).index(primary_station_ID)]\n",
        "else:\n",
        "  primary_station_name = get_station_name(primary_station_ID)\n",
        "\n",
        "# Get primary station data into df\n",
        "API_URL = create_URL(start_date, end_date, primary_station_ID)\n",
        "dict_data = download_API_data(API_URL)\n",
        "composite_df = pd.DataFrame.from_dict(dict_data, orient='index', columns=[primary_station_name])\n",
        "composite_df = remove_unreasonable_times(composite_df)\n",
        "\n",
        "# Data wrangling to get google drive df\n",
        "primary_station_df = composite_df.copy()\n",
        "primary_station_df = primary_station_df.sort_values(primary_station_name, ascending=False)\n",
        "primary_station_df = primary_station_df.iloc[:x_top_tides, :]\n",
        "\n",
        "# Data wrangling to get final composite df\n",
        "composite_df = consolidate_dates(composite_df)\n",
        "composite_df = sort_and_rank(composite_df, primary_station_name)\n",
        "\n",
        "# Create new sheet for primary station and write to it\n",
        "sh.add_worksheet(title=primary_station_name, rows=primary_station_df.shape[0], cols=3)\n",
        "worksheet = sh.worksheet(primary_station_name)\n",
        "worksheet.update('A1', [['Date']] + [[x.split()[0]] for x in primary_station_df.index.values])\n",
        "worksheet.update('B1', [['Time']] + [[x.split()[1]] for x in primary_station_df.index.values])\n",
        "worksheet.update('C1', ([primary_station_df.columns.values.tolist()] + primary_station_df.values.tolist()))"
      ],
      "metadata": {
        "id": "axapT93-PkJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb82be88-0746-4483-fec0-57f5094cb966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1CYcDLFqS5TP15u6vjgJBt-WS1oy-R4oegCeNrPA2eGI',\n",
              " 'updatedCells': 26,\n",
              " 'updatedColumns': 1,\n",
              " 'updatedRange': 'Honolulu!C1:C26',\n",
              " 'updatedRows': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 766
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download, data wrangling, and google sheets upload of all non-primary stations used in composite table."
      ],
      "metadata": {
        "id": "69_q-Mrvk9y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if has_multiple:\n",
        "  # Add each station's data to the composite df\n",
        "  for station in stations:\n",
        "\n",
        "    station_ID = stations[station]\n",
        "\n",
        "    if station_ID != primary_station_ID:\n",
        "      # Get station data into df\n",
        "      API_URL = create_URL(start_date, end_date, station_ID)\n",
        "      dict_data = download_API_data(API_URL)\n",
        "      station_df_composite = pd.DataFrame.from_dict(dict_data, orient='index', columns=[station])\n",
        "      station_df_composite = remove_unreasonable_times(station_df_composite)\n",
        "\n",
        "      # Data wrangling to get google sheets df\n",
        "      station_df_sheets = station_df_composite.copy()\n",
        "      station_df_sheets = station_df_sheets.sort_values(station, ascending=False)\n",
        "      station_df_sheets = station_df_sheets[:x_top_tides]\n",
        "\n",
        "      # Add google sheets df to google sheets\n",
        "      sh.add_worksheet(title=station, rows=station_df_sheets.shape[0], cols=3)\n",
        "      worksheet = sh.worksheet(station)\n",
        "      worksheet.update('A1', [['Date']] + [[x.split()[0]] for x in station_df_sheets.index.values])\n",
        "      worksheet.update('B1', [['Time']] + [[x.split()[1]] for x in station_df_sheets.index.values])\n",
        "      worksheet.update('C1', ([station_df_sheets.columns.values.tolist()] + station_df_sheets.values.tolist()))\n",
        "\n",
        "      # Data wrangling to get composite df\n",
        "      station_df_composite = consolidate_dates(station_df_composite)\n",
        "      station_df_composite = sort_and_rank(station_df_composite, station)\n",
        "\n",
        "      # Add station df to composite df\n",
        "      composite_df = composite_df.join(station_df_composite[station])\n",
        "\n",
        "  # Compute composite score\n",
        "  composite_df['Composite Score'] = composite_df.sum(axis=1)\n",
        "  composite_df = composite_df[:x_top_tides]\n",
        "\n",
        "  # Replace invalid dates with -1\n",
        "  rows_with_na = np.array(composite_df.isna().sum(axis=1))\n",
        "  composite_df.loc[rows_with_na > 0, 'Composite Score'] = -1\n",
        "  composite_df = composite_df.fillna(-1)\n",
        "  composite_df = composite_df.astype(int)\n",
        "\n",
        "  # Add composite table to google sheets\n",
        "  worksheet = sh.sheet1\n",
        "  worksheet.update_title(\"COMPOSITE SCORE\")\n",
        "  worksheet.update('A1', [['Date']] + [[x] for x in composite_df.index.values])\n",
        "  worksheet.update('B1', [composite_df.columns.values.tolist()] + composite_df.values.tolist())\n",
        "  worksheet.update(f\"A{x_top_tides+3}\", \"NOTE: Composite scores of -1 indicate that one of the stations don't have a reasonably timed high tide for that day\")\n",
        "\n",
        "# Custom composite page if only one station\n",
        "else:\n",
        "  worksheet = sh.sheet1\n",
        "  worksheet.update_title(\"COMPOSITE SCORE\")\n",
        "  worksheet.update('A1', f\"Only one harmonic station selected for [{region}] region, so there is no composite table\")"
      ],
      "metadata": {
        "id": "eCO4njmYPgBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composite_df.head(10)"
      ],
      "metadata": {
        "id": "Lb93L_FtThtd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1b0486-9ea5-4d1b-c0a2-df78a5f447da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Honolulu  PORT ALLEN, HANAPEPE BAY, KAUAI ISLAND  Nawiliwili  \\\n",
              "Date                                                                       \n",
              "2021-06-24         1                                       1           1   \n",
              "2021-07-22         2                                       2           2   \n",
              "2021-07-23         3                                       3           3   \n",
              "2021-06-23         4                                       4           5   \n",
              "2021-06-25         5                                       5           4   \n",
              "2021-07-21         6                                       6           6   \n",
              "2021-07-24         7                                       7           7   \n",
              "2021-05-26         8                                      10          11   \n",
              "2021-05-27         9                                      11          10   \n",
              "2021-08-20        10                                       8           8   \n",
              "\n",
              "            FORT KAMEHAMEHA, BISHOP POINT, PEARL HBR  \\\n",
              "Date                                                   \n",
              "2021-06-24                                         1   \n",
              "2021-07-22                                         2   \n",
              "2021-07-23                                         4   \n",
              "2021-06-23                                         3   \n",
              "2021-06-25                                         6   \n",
              "2021-07-21                                         5   \n",
              "2021-07-24                                         9   \n",
              "2021-05-26                                         7   \n",
              "2021-05-27                                        10   \n",
              "2021-08-20                                        12   \n",
              "\n",
              "            FORD ISLAND, FERRY DOCK, PEARL HARBOR  Mokuoloe  \\\n",
              "Date                                                          \n",
              "2021-06-24                                      1         1   \n",
              "2021-07-22                                      2         3   \n",
              "2021-07-23                                      3         2   \n",
              "2021-06-23                                      4         5   \n",
              "2021-06-25                                      5         4   \n",
              "2021-07-21                                      6         7   \n",
              "2021-07-24                                      7         6   \n",
              "2021-05-26                                      8        10   \n",
              "2021-05-27                                     12        11   \n",
              "2021-08-20                                      9         8   \n",
              "\n",
              "            Kaunakakai Harbor  Kahului, Kahului Harbor  Kawaihae  \\\n",
              "Date                                                               \n",
              "2021-06-24                  1                        2         1   \n",
              "2021-07-22                  4                        3         4   \n",
              "2021-07-23                  5                        1         2   \n",
              "2021-06-23                  2                        6         5   \n",
              "2021-06-25                  3                        4         3   \n",
              "2021-07-21                  9                       13         9   \n",
              "2021-07-24                  8                        5         6   \n",
              "2021-05-26                  6                       10         8   \n",
              "2021-05-27                  7                       11         7   \n",
              "2021-08-20                 13                        7        11   \n",
              "\n",
              "            Hilo, Hilo Bay, Kuhio Bay  Composite Score  \n",
              "Date                                                    \n",
              "2021-06-24                          1               11  \n",
              "2021-07-22                          4               28  \n",
              "2021-07-23                          2               28  \n",
              "2021-06-23                          5               43  \n",
              "2021-06-25                          3               42  \n",
              "2021-07-21                         12               79  \n",
              "2021-07-24                          6               68  \n",
              "2021-05-26                          7               85  \n",
              "2021-05-27                          8               96  \n",
              "2021-08-20                         10               96  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3d845e2-1dfe-442c-9233-aa3b1ee7dfe8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Honolulu</th>\n",
              "      <th>PORT ALLEN, HANAPEPE BAY, KAUAI ISLAND</th>\n",
              "      <th>Nawiliwili</th>\n",
              "      <th>FORT KAMEHAMEHA, BISHOP POINT, PEARL HBR</th>\n",
              "      <th>FORD ISLAND, FERRY DOCK, PEARL HARBOR</th>\n",
              "      <th>Mokuoloe</th>\n",
              "      <th>Kaunakakai Harbor</th>\n",
              "      <th>Kahului, Kahului Harbor</th>\n",
              "      <th>Kawaihae</th>\n",
              "      <th>Hilo, Hilo Bay, Kuhio Bay</th>\n",
              "      <th>Composite Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-06-24</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-22</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-23</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-23</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-25</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-21</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-24</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-26</th>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-27</th>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-20</th>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3d845e2-1dfe-442c-9233-aa3b1ee7dfe8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3d845e2-1dfe-442c-9233-aa3b1ee7dfe8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3d845e2-1dfe-442c-9233-aa3b1ee7dfe8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 768
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Developer Note:"
      ],
      "metadata": {
        "id": "OPr95Q_OrSbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code in the cell to get the primary station data previously sometimes generated a warning, but I believe it to be fixed now. I was using \n",
        "\n",
        "`primary_station_df = primary_station_df[:x_top_tides]` \n",
        "\n",
        "to drop everything but the first `x_top_tides` rows from the dataframe, but have since switched it to \n",
        "\n",
        "`primary_station_df = primary_station_df.iloc[:x_top_tides, :]`\n",
        "\n",
        "which is the recommended way, and appears to no longer generate the warning. The warning that would occassionally generate was as follows:\n",
        "\n",
        "> /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "> See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  from ipykernel import kernelapp as app"
      ],
      "metadata": {
        "id": "miKnHjJHv6OP"
      }
    }
  ]
}